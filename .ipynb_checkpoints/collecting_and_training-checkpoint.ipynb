{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from grabscreen import grab_screen\n",
    "import cv2\n",
    "import time\n",
    "from getkeys import key_check\n",
    "import os\n",
    "\n",
    "\n",
    "def keys_to_output(keys):\n",
    "    '''\n",
    "    Convert keys to a ...multi-hot... array\n",
    "    [A,W,D] boolean values.\n",
    "    '''\n",
    "    output = [0,0,0]\n",
    "    \n",
    "    if 'A' in keys:\n",
    "        output[0] = 1\n",
    "    elif 'D' in keys:\n",
    "        output[2] = 1\n",
    "    else:\n",
    "        output[1] = 1\n",
    "    return output\n",
    "\n",
    "\n",
    "file_name = 'training_data.npy'\n",
    "\n",
    "if os.path.isfile(file_name):\n",
    "    print('File exists, loading previous data!')\n",
    "    training_data = list(np.load(file_name,allow_pickle=True))\n",
    "else:\n",
    "    print('File does not exist, starting fresh!')\n",
    "    training_data = []\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    for i in list(range(4))[::-1]:\n",
    "        print(i+1)\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "    paused = False\n",
    "    while(True):\n",
    "\n",
    "        if not paused:\n",
    "            # 800x600 windowed mode\n",
    "            screen = grab_screen(region=(0,40,1920,1080))\n",
    "            last_time = time.time()\n",
    "            screen = cv2.cvtColor(screen, cv2.COLOR_BGR2GRAY)\n",
    "            screen = cv2.resize(screen, (160,120))\n",
    "            # resize to something a bit more acceptable for a CNN\n",
    "            keys = key_check()\n",
    "            output = keys_to_output(keys)\n",
    "            training_data.append([screen,output])\n",
    "            \n",
    "            if len(training_data) % 1000 == 0:\n",
    "                print(len(training_data))\n",
    "                np.save(file_name,training_data)\n",
    "\n",
    "        keys = key_check()\n",
    "        if 'T' in keys:\n",
    "            if paused:\n",
    "                paused = False\n",
    "                print('unpaused!')\n",
    "                time.sleep(1)\n",
    "            else:\n",
    "                print('Pausing!')\n",
    "                paused = True\n",
    "                time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "train_data = np.load('training_data.npy',allow_pickle=True)\n",
    "for data in train_data:\n",
    "    img=data[0]\n",
    "    choice=data[1]\n",
    "    cv2.imshow('test',img)\n",
    "    print(choice)\n",
    "    if cv2.waitKey(25)& 0x7FF ==ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "\n",
    "train_data = np.load('training_data_v2.npy',allow_pickle=True)\n",
    "\n",
    "df = pd.DataFrame(train_data)\n",
    "print(df.head())\n",
    "print(Counter(df[1].apply(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lefts = []\n",
    "rights = []\n",
    "forwards = []\n",
    "\n",
    "shuffle(train_data)\n",
    "\n",
    "for data in train_data:\n",
    "    img = data[0]\n",
    "    choice = data[1]\n",
    "\n",
    "    if choice == [1,0,0]:\n",
    "        lefts.append([img,choice])\n",
    "    elif choice == [0,1,0]:\n",
    "        forwards.append([img,choice])\n",
    "    elif choice == [0,0,1]:\n",
    "        rights.append([img,choice])\n",
    "    else:\n",
    "        print('no matches')\n",
    "\n",
    "\n",
    "forwards = forwards[:len(lefts)][:len(rights)]\n",
    "lefts = lefts[:len(forwards)]\n",
    "rights = rights[:len(forwards)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = forwards + lefts + rights\n",
    "shuffle(final_data)\n",
    "\n",
    "np.save('training_data_v2.npy', final_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "\n",
    "def alexnet(width, height, lr):\n",
    "    network = input_data(shape=[None, width, height, 1], name='input')\n",
    "    network = conv_2d(network, 96, 11, strides=4, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 256, 5, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = conv_2d(network, 256, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "   \n",
    "    network = fully_connected(network, 4096, activation='tanh')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, 4096, activation='tanh')\n",
    "    network = dropout(network, 0.5)\n",
    "   \n",
    "    network = fully_connected(network, 3, activation='softmax')\n",
    "    network = regression(network, optimizer='momentum',\n",
    "                         loss='categorical_crossentropy',\n",
    "                         learning_rate=lr, name='targets')\n",
    "\n",
    "    model = tflearn.DNN(network, checkpoint_path='model_alexnet',\n",
    "                        max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir='log')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "WIDTH =160\n",
    "HEIGHT =120\n",
    "LR = 1e-3\n",
    "EPOCHS = 60\n",
    "MODEL_NAME = 'tadmad2.model'.format(LR, 'alexnetv2',EPOCHS)\n",
    "\n",
    "model = alexnet(WIDTH, HEIGHT, LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('training_data_v2.npy',allow_pickle=True)\n",
    "\n",
    "train = train_data[:-500]\n",
    "test = train_data[-500:]\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "X = np.array([i[0] for i in train]).reshape(-1,WIDTH,HEIGHT,1)\n",
    "Y = [i[1] for i in train]\n",
    "print(len(X))\n",
    "print(len(Y))\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,WIDTH,HEIGHT,1)\n",
    "test_y = [i[1] for i in test]\n",
    "print(len(test_x))\n",
    "print(len(test_y))\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "#set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit({'input': X}, {'targets': Y}, n_epoch=EPOCHS, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "            snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
    "\n",
    "\n",
    "\n",
    "#tensorboard --logdir=foo:C:\\Windows\\System32\\witchermodel\\log\n",
    "\n",
    "\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
